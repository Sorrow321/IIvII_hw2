## Build

```
$ docker build -t iivii2 .
```

## Run
```
$ docker run --gpus all -it --entrypoint=/bin/bash iivii2
$ python3 solution.py
```

## Описание решения
Модифицирован код библиотек dalle2-laion и dalle2-pytorch (изменены два файла, лежат в ./modified_files. Начало и конец моих добавлений/исправлений помечены комментариями "### HW CODE START ###" и "### HW CODE END ###"). Веса нейросетей не изменялись. Исходная картинка и текст (несколько текстовых описаний из COCO) загружаются в PyTorch Dataset в двух вариантах: низкое разрешение (64х64) и высокое разрешение (256х256). Картинка размером 64х64 ресайзится до 256х256, получается размытая картинка. Эта размытая картинка используется в качестве condition для второго декодера. Помимо нее параметрами идут: text embedding, image embedding. Такой подход позволяет получить значение метрики около 30 в среднем на пяти представленных в решении картинках (выбраны случайно). Также был реализован второй метод: оптимизация латентов по ходу расшумления. Однако данный метод на практике снижает метрику и делает выходную картинку заблюренной. Именно в этом методы используется картинка 256x256, для подсчета лосса. Для проверки данного метода следует раскомментировать соответствующий код в файле modified_files/dalle2_pytorch.py

## Запуск решения на своих картинках
Для того чтобы подсчитать значения метрики на своем наборе картинок, данные изображения и соответствующие им текстовые описания надо разместить в ./img_for_test по аналогии с тем, как это сделано в примере.